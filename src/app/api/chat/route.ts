import { NextRequest } from 'next/server';
import { SegmentWithRelations } from "@/lib/db/speakerSegments";
import { search, SearchResultDetailed, SearchConfig } from '@/lib/search';
import { PersonWithRelations } from '@/lib/db/people';
import { ChatMessage } from '@/types/chat';
import { aiChatStream, AIConfig } from '@/lib/ai';
import { findSubjectsByQuery } from '@/lib/seed-data';
import { 
    findMockSpeakerSegmentsForSubject,
    generateMockClaudeResponse 
} from '@/lib/db/chat-mock-data';

// Define types for our content extraction
interface ExtractedSegment {
    speaker: string;
    text: string;
    person: PersonWithRelations | null;
}

interface ExtractedSubject {
    name: string;
    description: string;
    topic?: string;
    context?: string;
    keySegments: ExtractedSegment[];
    speakerSegments: ExtractedSegment[];
}

// Search Configuration
const searchConfig: SearchConfig = {
    size: 5,
    enableSemanticSearch: true,
    rankWindowSize: 100,
    rankConstant: 60,
    detailed: true // We need detailed results for chat
};

// Context Management
const CONTEXT_CONFIG = {
    maxMessages: 10,
    maxTokens: 10000,
    useAllSegments: true,
};

// AI Configuration
const AI_CONFIG: AIConfig = {
    maxTokens: 1000,
    model: 'claude-3-5-sonnet-20240620',
    temperature: 0,

};

// @TODO: Better logging in the future
// Helper function for essential logs that should always be shown
const logEssential = (message: string, data?: any) => {
    console.log(`[Chat Analytics] ${message}`, data || '');
};

// Helper function for development-only logs
const logDev = (message: string, data?: any) => {
    if (process.env.NODE_ENV === 'development') {
        console.log(`[Dev] ${message}`, data || '');
    }
};

// Content Extraction
function extractRelevantContent(searchResults: SearchResultDetailed[]): ExtractedSubject[] {
    logDev(`[Content Extraction] Processing ${searchResults.length} search results`);
    
    const extracted = searchResults.map(result => {
        // Get matched segments from the detailed results
        const matchedSegments = (result.speakerSegments as SegmentWithRelations[])
            .filter(segment => result.matchedSpeakerSegmentIds?.includes(segment.id));
            
        logDev(`[Content Extraction] Subject "${result.name}":`, {
            score: result.score,
            totalSegments: result.speakerSegments.length,
            matchedSegments: matchedSegments.length,
            hasContext: result.context ? 'Yes' : 'No'
        });
        
        return {
            name: result.name,
            description: result.description,
            topic: result.topic?.name,
            context: result.context,
            keySegments: matchedSegments.map(segment => ({
                speaker: segment.person?.name || 'Unknown',
                text: segment.text,
                person: segment.person
            })),
            speakerSegments: (result.speakerSegments as SegmentWithRelations[]).map(segment => ({
                speaker: segment.person?.name || 'Unknown',
                text: segment.text,
                person: segment.person
            }))
        };
    });

    logDev(`[Content Extraction] Total segments extracted: ${extracted.reduce((acc, curr) => acc + curr.keySegments.length, 0)}`);
    return extracted;
}

// Utility function to clean context of references
function cleanContextReferences(context: string | undefined): string | undefined {
    if (!context) return undefined;
    // Remove references in the format [X] where X is any number
    return context.replace(/\[\d+\]/g, '');
}

// Context Enhancement
function enhancePrompt(
    messages: ChatMessage[],
    context: ReturnType<typeof extractRelevantContent>
) {
    logDev(`[Prompt Enhancement] Enhancing prompt with:`, {
        messages: messages.length,
        contextSubjects: context.length,
        useAllSegments: CONTEXT_CONFIG.useAllSegments
    });
    
    const systemPrompt = `${SYSTEM_PROMPT}

Î£Ï‡ÎµÏ„Î¹ÎºÎ¬ Î¸Î­Î¼Î±Ï„Î± ÏƒÏ…Î¼Î²Î¿Ï…Î»Î¯Î¿Ï… (Î¼Îµ ÏƒÎµÎ¹ÏÎ¬ Ï€ÏÎ¿Ï„ÎµÏÎ±Î¹ÏŒÏ„Î·Ï„Î±Ï‚):
${context.map((subject, index) => {
    logDev(`[Prompt Enhancement] Processing subject ${index + 1}:`, {
        totalSegments: subject.speakerSegments.length,
        keySegments: subject.keySegments.length,
        hasContext: subject.context ? 'Yes' : 'No'
    });
    
    return `
----------------------------------------
[${index + 1}] Î˜Î­Î¼Î±: ${subject.name}
${subject.topic ? `ÎšÎ±Ï„Î·Î³Î¿ÏÎ¯Î±: ${subject.topic}` : ''}
Î ÎµÏÎ¹Î³ÏÎ±Ï†Î®: ${subject.description}
${subject.context ? `\nÎ ÏÏŒÏƒÎ¸ÎµÏ„Î¿ Ï€ÎµÏÎ¹ÎµÏ‡ÏŒÎ¼ÎµÎ½Î¿ Î³Î¹Î± Ï„Î¿ Î¸Î­Î¼Î±: ${cleanContextReferences(subject.context)}` : ''}

Î‘Ï€Î¿ÏƒÏ€Î¬ÏƒÎ¼Î±Ï„Î± Î¿Î¼Î¹Î»Î¹ÏŽÎ½:
${CONTEXT_CONFIG.useAllSegments 
    ? subject.speakerSegments.map(segment => {
        const isKeySegment = subject.keySegments.some(keySeg => keySeg.text === segment.text);
        const prefix = isKeySegment && CONTEXT_CONFIG.useAllSegments ? 'ðŸ”¹ ' : 'â€¢ ';
        const partyName = segment.person?.roles?.[0]?.party?.name || 'Î‘Î½ÎµÎ¾Î¬ÏÏ„Î·Ï„Î¿Ï‚';
        return `${prefix}${segment.speaker} (${partyName}): "${segment.text}"`;
    }).join('\n')
    : subject.keySegments.map(segment => {
        const partyName = segment.person?.roles?.[0]?.party?.name || 'Î‘Î½ÎµÎ¾Î¬ÏÏ„Î·Ï„Î¿Ï‚';
        return `â€¢ ${segment.speaker} (${partyName}): "${segment.text}"`;
    }).join('\n')
}
----------------------------------------`}).join('\n\n')}

${CONTEXT_CONFIG.useAllSegments ? 'Î£Î·Î¼ÎµÎ¯Ï‰ÏƒÎ·: Î¤Î± Î±Ï€Î¿ÏƒÏ€Î¬ÏƒÎ¼Î±Ï„Î± Î¼Îµ ðŸ”¹ ÎµÎ¯Î½Î±Î¹ Ï„Î± Ï€Î¹Î¿ ÏƒÏ‡ÎµÏ„Î¹ÎºÎ¬ Î¼Îµ Ï„Î·Î½ ÎµÏÏŽÏ„Î·ÏƒÎ® ÏƒÎ±Ï‚.' : ''}`;

    // Log approximate token count
    const approximateTokens = systemPrompt.split(/\s+/).length;
    logDev(`[Prompt Enhancement] Approximate token count: ${approximateTokens}`);

    // Strip out id field from messages before sending to Claude
    const cleanedMessages = messages.slice(-CONTEXT_CONFIG.maxMessages).map(({ role, content }) => ({
        role,
        content
    }));

    logDev(`[Prompt Enhancement] Sending ${cleanedMessages.length} cleaned messages to Claude`);

    return {
        system: systemPrompt,
        messages: cleanedMessages
    };
}

// Constants
const SYSTEM_PROMPT = `Î•Î¯ÏƒÏ„Îµ Î­Î½Î±Ï‚ ÎµÎ¾ÎµÎ¹Î´Î¹ÎºÎµÏ…Î¼Î­Î½Î¿Ï‚ Î²Î¿Î·Î¸ÏŒÏ‚ AI Î³Î¹Î± Ï„Î¿ OpenCouncil, Î¼Î¹Î± Ï€Î»Î±Ï„Ï†ÏŒÏÎ¼Î± Ï€Î¿Ï… Ï€Î±ÏÎ­Ï‡ÎµÎ¹ Ï€ÏÏŒÏƒÎ²Î±ÏƒÎ· ÏƒÎµ Î¼ÎµÏ„Î±Î³ÏÎ±Ï†Î­Ï‚ ÎºÎ±Î¹ Î´ÎµÎ´Î¿Î¼Î­Î½Î± Î±Ï€ÏŒ ÏƒÏ…Î½ÎµÎ´ÏÎ¹Î¬ÏƒÎµÎ¹Ï‚ Î´Î·Î¼Î¿Ï„Î¹ÎºÏŽÎ½ ÏƒÏ…Î¼Î²Î¿Ï…Î»Î¯Ï‰Î½. 

Î¡ÏŒÎ»Î¿Ï‚ ÎºÎ±Î¹ Î”ÎµÎ´Î¿Î¼Î­Î½Î±:
- Î•Î¯ÏƒÏ„Îµ ÎµÎ¹Î´Î¹ÎºÏŒÏ‚ ÏƒÏ„Î· Î´Î·Î¼Î¿Ï„Î¹ÎºÎ® Î´Î¹Î±ÎºÏ…Î²Î­ÏÎ½Î·ÏƒÎ· ÎºÎ±Î¹ Ï„Î¹Ï‚ Î´Î¹Î±Î´Î¹ÎºÎ±ÏƒÎ¯ÎµÏ‚ Ï„Ï‰Î½ Î´Î·Î¼Î¿Ï„Î¹ÎºÏŽÎ½ ÏƒÏ…Î¼Î²Î¿Ï…Î»Î¯Ï‰Î½
- ÎˆÏ‡ÎµÏ„Îµ Ï€ÏÏŒÏƒÎ²Î±ÏƒÎ· ÏƒÎµ Î¼ÎµÏ„Î±Î³ÏÎ±Ï†Î­Ï‚ ÏƒÏ…Î½ÎµÎ´ÏÎ¹Î¬ÏƒÎµÏ‰Î½, Î¸Î­Î¼Î±Ï„Î± ÏƒÏ…Î¼Î²Î¿Ï…Î»Î¯Î¿Ï…, ÎºÎ±Î¹ ÏƒÏ‡ÎµÏ„Î¹ÎºÎ¬ Î´ÎµÎ´Î¿Î¼Î­Î½Î±
- ÎœÏ€Î¿ÏÎµÎ¯Ï„Îµ Î½Î± Î±Î½Î±Ï†Î­ÏÎµÏƒÏ„Îµ ÏƒÎµ ÏƒÏ…Î³ÎºÎµÎºÏÎ¹Î¼Î­Î½Î± Î¸Î­Î¼Î±Ï„Î± ÏƒÏ…Î¼Î²Î¿Ï…Î»Î¯Î¿Ï… ÎºÎ±Î¹ Î±Ï€Î¿ÏƒÏ€Î¬ÏƒÎ¼Î±Ï„Î± Î¿Î¼Î¹Î»Î¹ÏŽÎ½

Î¤ÏÏ€Î¿Î¹ Î•ÏÏ‰Ï„Î®ÏƒÎµÏ‰Î½:
- Î•ÏÏ‰Ï„Î®ÏƒÎµÎ¹Ï‚ Î³Î¹Î± Î´Î¹Î±Î´Î¹ÎºÎ±ÏƒÎ¯ÎµÏ‚ Î´Î·Î¼Î¿Ï„Î¹ÎºÏŽÎ½ ÏƒÏ…Î¼Î²Î¿Ï…Î»Î¯Ï‰Î½
- Î•ÏÏ‰Ï„Î®ÏƒÎµÎ¹Ï‚ Î³Î¹Î± ÏƒÏ…Î³ÎºÎµÎºÏÎ¹Î¼Î­Î½Î± Î¸Î­Î¼Î±Ï„Î± ÏƒÏ…Î¼Î²Î¿Ï…Î»Î¯Î¿Ï…
- Î•ÏÏ‰Ï„Î®ÏƒÎµÎ¹Ï‚ Î³Î¹Î± Î±ÏƒÏ„Î¹ÎºÏŒ ÏƒÏ‡ÎµÎ´Î¹Î±ÏƒÎ¼ÏŒ ÎºÎ±Î¹ Ï€Î¿Î»Î¹Ï„Î¹ÎºÎ­Ï‚
- Î•ÏÏ‰Ï„Î®ÏƒÎµÎ¹Ï‚ Î³Î¹Î± ÏƒÏ…Î¼Î²Î¿ÏÎ»Î¿Ï…Ï‚ ÎºÎ±Î¹ ÎºÏŒÎ¼Î¼Î±Ï„Î±
- Î•ÏÏ‰Ï„Î®ÏƒÎµÎ¹Ï‚ Î³Î¹Î± Ï„Î¿Ï€Î¹ÎºÎ¬ Î¸Î­Î¼Î±Ï„Î± ÎºÎ±Î¹ Ï€ÏÎ¿Î²Î»Î®Î¼Î±Ï„Î±

Î“ÎµÎ½Î¹ÎºÎ­Ï‚ ÎŸÎ´Î·Î³Î¯ÎµÏ‚:
- Î Î±ÏÎ­Ï‡ÎµÏ„Îµ Î±ÎºÏÎ¹Î²ÎµÎ¯Ï‚ ÎºÎ±Î¹ ÎµÎ½Î·Î¼ÎµÏÏ‰Ï„Î¹ÎºÎ­Ï‚ Î±Ï€Î±Î½Ï„Î®ÏƒÎµÎ¹Ï‚
- Î‘Ï€Î±Î½Ï„Î®ÏƒÏ„Îµ Î¬Î¼ÎµÏƒÎ± ÎºÎ±Î¹ ÏƒÏ…Î½Î¿Ï€Ï„Î¹ÎºÎ¬ Ï‡Ï‰ÏÎ¯Ï‚ Ï€ÎµÏÎ¹Ï„Ï„Î­Ï‚ ÎµÎ¹ÏƒÎ±Î³Ï‰Î³Î­Ï‚
- Î§ÏÎ·ÏƒÎ¹Î¼Î¿Ï€Î¿Î¹Î®ÏƒÏ„Îµ Ï„Î± Î´ÎµÎ´Î¿Î¼Î­Î½Î± Ï„Î¿Ï… context Î³Î¹Î± Î½Î± Ï…Ï€Î¿ÏƒÏ„Î·ÏÎ¯Î¾ÎµÏ„Îµ Ï„Î¹Ï‚ Î±Ï€Î±Î½Ï„Î®ÏƒÎµÎ¹Ï‚ ÏƒÎ±Ï‚
- ÎŒÏ„Î±Î½ Î±Î½Î±Ï†Î­ÏÎµÏƒÏ„Îµ ÏƒÎµ Î¸Î­Î¼Î±Ï„Î±, Ï‡ÏÎ·ÏƒÎ¹Î¼Î¿Ï€Î¿Î¹Î®ÏƒÏ„Îµ Ï„Î·Î½ Î±Î½Î±Ï†Î¿ÏÎ¬ [X] ÏŒÏ€Î¿Ï… X ÎµÎ¯Î½Î±Î¹ Î¿ Î±ÏÎ¹Î¸Î¼ÏŒÏ‚ Ï„Î¿Ï… Î¸Î­Î¼Î±Ï„Î¿Ï‚
- Î‘Î½ Î´ÎµÎ½ Î³Î½Ï‰ÏÎ¯Î¶ÎµÏ„Îµ Ï„Î·Î½ Î±Ï€Î¬Î½Ï„Î·ÏƒÎ·, Ï€ÎµÎ¯Ï„Îµ Ï„Î¿ Î¾ÎµÎºÎ¬Î¸Î±ÏÎ±
- ÎœÎ·Î½ ÎµÏ€Î¹Î½Î¿ÎµÎ¯Ï„Îµ Ï€Î»Î·ÏÎ¿Ï†Î¿ÏÎ¯ÎµÏ‚

Î¤ÏŒÎ½Î¿Ï‚ ÎºÎ±Î¹ Î“Î»ÏŽÏƒÏƒÎ±:
- Î§ÏÎ·ÏƒÎ¹Î¼Î¿Ï€Î¿Î¹Î®ÏƒÏ„Îµ ÎµÏ€Î±Î³Î³ÎµÎ»Î¼Î±Ï„Î¹ÎºÏŒ Î±Î»Î»Î¬ Ï€ÏÎ¿ÏƒÎ¹Ï„ÏŒ Ï„ÏŒÎ½Î¿
- Î§ÏÎ·ÏƒÎ¹Î¼Î¿Ï€Î¿Î¹Î®ÏƒÏ„Îµ Ï„ÎµÏ‡Î½Î¹ÎºÎ¿ÏÏ‚ ÏŒÏÎ¿Ï…Ï‚ ÏŒÏ€Î¿Ï… ÎµÎ¯Î½Î±Î¹ Î±Ï€Î±ÏÎ±Î¯Ï„Î·Ï„Î¿, Î±Î»Î»Î¬ ÎµÎ¾Î·Î³Î®ÏƒÏ„Îµ Ï„Î¿Ï…Ï‚ ÏŒÏ„Î±Î½ Ï‡ÏÎµÎ¹Î¬Î¶ÎµÏ„Î±Î¹
- Î”Î¹Î±Ï„Î·ÏÎ®ÏƒÏ„Îµ Î±Î½Ï„Î¹ÎºÎµÎ¹Î¼ÎµÎ½Î¹ÎºÏŒÏ„Î·Ï„Î± ÎºÎ±Î¹ Î¹ÏƒÎ¿ÏÏÎ¿Ï€Î¯Î± ÏƒÏ„Î¹Ï‚ Î±Ï€Î±Î½Ï„Î®ÏƒÎµÎ¹Ï‚

ÎœÎ¿ÏÏ†Î¿Ï€Î¿Î¯Î·ÏƒÎ·:
- Î§ÏÎ·ÏƒÎ¹Î¼Î¿Ï€Î¿Î¹Î®ÏƒÏ„Îµ Î»Î¯ÏƒÏ„ÎµÏ‚ Î³Î¹Î± ÏƒÏÎ½Ï„Î¿Î¼ÎµÏ‚ Î±Ï€Î±Î½Ï„Î®ÏƒÎµÎ¹Ï‚
- Î§Ï‰ÏÎ¯ÏƒÏ„Îµ Î¼ÎµÎ³Î¬Î»ÎµÏ‚ Î±Ï€Î±Î½Ï„Î®ÏƒÎµÎ¹Ï‚ ÏƒÎµ Ï€Î±ÏÎ±Î³ÏÎ¬Ï†Î¿Ï…Ï‚
- Î•Ï€Î¹ÏƒÎ®Î¼Î±Î½Îµ ÏƒÎ·Î¼Î±Î½Ï„Î¹ÎºÎ¬ ÏƒÎ·Î¼ÎµÎ¯Î± Î¼Îµ Î­Î¼Ï†Î±ÏƒÎ· ÏŒÏ€Î¿Ï… Ï‡ÏÎµÎ¹Î¬Î¶ÎµÏ„Î±Î¹
- ÎŒÏ„Î±Î½ Î±Î½Î±Ï†Î­ÏÎµÏƒÏ„Îµ ÏƒÎµ Î¸Î­Î¼Î±Ï„Î±, Ï‡ÏÎ·ÏƒÎ¹Î¼Î¿Ï€Î¿Î¹Î®ÏƒÏ„Îµ Ï€Î¬Î½Ï„Î± Ï„Î·Î½ Î±Î½Î±Ï†Î¿ÏÎ¬ [X] Î³Î¹Î± ÏƒÏ…Î½Î­Ï€ÎµÎ¹Î±`;

const ERROR_MESSAGE = "Î£Ï…Î³Î³Î½ÏŽÎ¼Î·, Ï€Î±ÏÎ¿Ï…ÏƒÎ¹Î¬ÏƒÏ„Î·ÎºÎµ ÏƒÏ†Î¬Î»Î¼Î± ÎºÎ±Ï„Î¬ Ï„Î·Î½ ÎµÏ€ÎµÎ¾ÎµÏÎ³Î±ÏƒÎ¯Î± Ï„Î¿Ï… Î±Î¹Ï„Î®Î¼Î±Ï„ÏŒÏ‚ ÏƒÎ±Ï‚. Î Î±ÏÎ±ÎºÎ±Î»ÏŽ Î´Î¿ÎºÎ¹Î¼Î¬ÏƒÏ„Îµ Î¾Î±Î½Î¬.";

// Helper function to determine if we should use mock data
function shouldUseMockData(useMockData: boolean): boolean {
    return useMockData && process.env.NODE_ENV === 'development';
}

export async function POST(req: NextRequest) {
    const encoder = new TextEncoder();
    const decoder = new TextDecoder();

    // Create a transform stream for the AI response
    const stream = new TransformStream();
    const writer = stream.writable.getWriter();

    // Start the streaming response immediately
    const streamResponse = new Response(stream.readable, {
        headers: {
            'Content-Type': 'text/event-stream',
            'Cache-Control': 'no-cache',
            'Connection': 'keep-alive',
        },
    });

    // Process the request asynchronously
    (async () => {
        try {
            logEssential('Chat Session Started');
            const { messages, cityId, useMockData } = await req.json();
            
            // Log request details
            logEssential('Chat Request Details', {
                messages: messages.length,
                cityId: cityId || 'none',
                useMockData: shouldUseMockData(useMockData),
                lastMessage: messages[messages.length - 1].content.substring(0, 50)
            });

            let searchResults: SearchResultDetailed[] = [];

            if (shouldUseMockData(useMockData)) {
                // Use seed data for development/testing
                const subjects = findSubjectsByQuery(messages[messages.length - 1].content, cityId);
                searchResults = subjects.map(subject => {
                    // Get mock speaker segments for this subject
                    const mockSegments = findMockSpeakerSegmentsForSubject(subject.name);
                    
                    return {
                        ...subject,
                        score: 1.0,
                        speakerSegments: mockSegments,
                        matchedSpeakerSegmentIds: mockSegments.map(s => s.id),
                        context: subject.context || null,
                        highlights: [],
                        location: null,
                        topic: null,
                        introducedBy: null
                    };
                }) as unknown as SearchResultDetailed[];
            } else {
                // Perform real search
                const searchResponse = await search({
                    query: messages[messages.length - 1].content,
                    cityIds: cityId ? [cityId] : undefined,
                    config: {
                        ...searchConfig,
                        detailed: true
                    }
                });

                if (!searchResponse.results.every(result => 'speakerSegments' in result)) {
                    throw new Error('Search results do not contain detailed speaker segments');
                }

                searchResults = searchResponse.results as SearchResultDetailed[];
            }

            logEssential('Search Results', {
                count: searchResults.length,
                useMockData: useMockData || false
            });

            // 2. Extract content
            const context = extractRelevantContent(searchResults);

            // 3. Enhance prompt
            const enhancedPrompt = enhancePrompt(messages, context);

            // 4. Get LLM response
            logEssential('Sending request to Claude');
            const claudeResponse = shouldUseMockData(useMockData)
                ? generateMockClaudeResponse(messages, searchResults)
                : await aiChatStream(
                    enhancedPrompt.system,
                    enhancedPrompt.messages,
                    AI_CONFIG
                );

            // 5. Track subjects
            const subjectReferences = searchResults;

            logEssential('Chat Response Prepared', {
                subjectReferences: subjectReferences.length,
                streaming: true,
                useMockData: useMockData || false
            });

            // Keep track of the accumulated content
            let accumulatedContent = '';
            let lastChunkTime = Date.now();
            const CHUNK_INTERVAL = 16; // ~60fps for smoother updates

            // Process each chunk from Claude
            for await (const chunk of claudeResponse) {
                if (chunk.type === 'content_block_delta') {
                    // The chunk delta may contain text content
                    const deltaText = chunk.delta && 'text' in chunk.delta ? chunk.delta.text || '' : '';

                    // Append the chunk text to the accumulated content
                    accumulatedContent += deltaText;

                    // Only send chunks at a reasonable interval to prevent flickering
                    const now = Date.now();
                    if (now - lastChunkTime >= CHUNK_INTERVAL) {
                        // Send the delta to the client
                        const data = {
                            id: Date.now().toString(),
                            role: 'assistant',
                            content: accumulatedContent,
                            done: false
                        };
                        await writer.write(encoder.encode(`data: ${JSON.stringify(data)}\n\n`));
                        lastChunkTime = now;
                    }
                }
            }

            // Send one final chunk with the complete content
            const finalData = {
                id: Date.now().toString(),
                role: 'assistant',
                content: accumulatedContent,
                done: false
            };
            await writer.write(encoder.encode(`data: ${JSON.stringify(finalData)}\n\n`));

            // Send the final message with subjects
            const completeData = {
                id: Date.now().toString(),
                role: 'assistant',
                content: accumulatedContent,
                subjectReferences,
                done: true
            };
            await writer.write(encoder.encode(`data: ${JSON.stringify(completeData)}\n\n`));

            // Close the stream
            await writer.close();
            
            logEssential('Chat Session Completed');
        } catch (error) {
            console.error(`[Chat API] Error:`, error);
            
            // Send an error message to the client
            const errorData = {
                id: Date.now().toString(),
                role: 'assistant',
                content: ERROR_MESSAGE,
                subjectReferences: [],
                error: true,
                done: true
            };

            try {
                await writer.write(encoder.encode(`data: ${JSON.stringify(errorData)}\n\n`));
                await writer.close();
            } catch (e) {
                console.error('Error writing to stream:', e);
            }
            
            logEssential('Chat Session Failed', {
                error: error instanceof Error ? error.message : 'Unknown error'
            });
        }
    })();

    return streamResponse;
} 